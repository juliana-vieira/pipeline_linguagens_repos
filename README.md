# Pipeline de extra√ß√£o de linguagens de programa√ß√£o de reposit√≥rios Github

- [English Version](#english-version)

Esse projeto implementa um pipeline de dados em Python, usando Programa√ß√£o Orientada a Objetos (POO), para extrair dados das principais linguagens de programa√ß√£o utilizadas por grandes empresas. Entre as empresas analisadas, est√£o Amazon, Spotify, Netflix, Discord, entre outras. O pipeline foi desenvolvido para extrair dados diretamente dos perfis dessas empresas no GitHub, mas √© um pipeline flex√≠vel que pode ser utilizado para extrair dados de qualquer perfil.

Projeto desenvolvido durante a forma√ß√£o de Engenharia de Dados da Alura, com pequenas modifica√ß√µes para otimizar a automa√ß√£o do processo de ETL.

## Tabela de Conte√∫dos
- [Caracter√≠sticas](#caracter√≠sticas)
- [Requisitos](#requisitos)
- [Configura√ß√£o e Uso](#configura√ß√£o-e-uso)
- [Exemplo de Uso](#exemplo-de-uso)

## Caracter√≠sticas

- Extrai dados sobre as linguagens de programa√ß√£o mais usadas em cada reposit√≥rio p√∫blico de perfis do GitHub.
- Flex√≠vel e extens√≠vel: basta informar o nome de usu√°rio do GitHub para extrair dados de qualquer perfil.
- Estrutura modular baseada em POO, permitindo f√°cil expans√£o e manuten√ß√£o.

## Requisitos

- Python 3.x
- Bibliotecas Python:
  - `requests`
  - `pandas`
  - `python-dotenv` e `os` (opcional, para gerenciamento seguro de tokens de acesso)

## Configura√ß√£o e Uso

1. **Clone o reposit√≥rio**:
   ```bash
   git clone https://github.com/juliana-vieira/pipeline_linguagens_repos.git
   cd pipeline_linguagens_repos

2. **Configura√ß√£o do Token de Acesso**:
   Para evitar limita√ß√µes de taxa ao acessar a API do GitHub, √© recomend√°vel configurar um token de acesso pessoal.

   - Crie um token de acesso no GitHub.
   - Armazene o token em uma vari√°vel de ambiente chamada `GITHUB_TOKEN` ou em um arquivo `.env`:
     ```plaintext
     GITHUB_TOKEN=seu_token_aqui
     ```

3. **Instale as depend√™ncias**:
   ```bash
   pip install -r requirements.txt

## Exemplo de Uso

Para extrair dados das linguagens de programa√ß√£o utilizadas por empresas, defina a lista `company_list` com os nomes de usu√°rio desejados:

```python
from processamento import DadosRepositorios

# Lista de empresas (ou qualquer usu√°rio GitHub) a serem analisadas
company_list = ["amzn", "netflix", "spotify", "discord"]

for company in company_list:

    dados = DadosRepositorios(company) # Cria um objeto da classe DadosRepositorios, que possui os m√©todos de extra√ß√£o de dados consumindo a API do Github
    dados.to_dataframe() # Transforma os dados para um DataFrame pandas
    dados.save_csv() # Salva o arquivo em CSV na pasta "data"
```

O c√≥digo acima ir√° criar um arquivo CSV para cada perfil listado em `company_list`, contendo os dados das principais linguagens de programa√ß√£o utilizadas por cada empresa, e salvar esses arquivos na pasta "data".

A clase DadosRepositorios possui todos os m√©todos necess√°rios para extrair os dados, transform√°-los e salv√°-los dentro do contexto do neg√≥cio.

üéâ **Obrigada por conferir este projeto!** üòä

--

## English Version

# Pipeline for Extracting Programming Languages from GitHub Repositories

This project implements a data pipeline in Python using Object-Oriented Programming (OOP) to extract data on the main programming languages used by large companies. The companies analyzed include Amazon, Spotify, Netflix, Discord, and others. The pipeline was developed to extract data directly from these companies' profiles on GitHub, but it is flexible and can be used to extract data from any profile.

The project was developed as part of Alura's Data Engineering training program, with small modifications to optimize the ETL process automation.

## Table of Contents
- [Features](#features)
- [Requirements](#requirements)
- [Setup and Usage](#setup-and-usage)
- [Usage Example](#usage-example)

## Features

- Extracts data on the most-used programming languages in each public repository of GitHub profiles.
- Flexible and extensible: just provide the GitHub username to extract data from any profile.
- Modular OOP-based structure, enabling easy expansion and maintenance.

## Requirements

- Python 3.x
- Python libraries:
  - `requests`
  - `pandas`
  - `python-dotenv` and `os` (optional, for secure management of access tokens)

## Setup and Usage

1. **Clone the repository**:
   ```bash
   git clone https://github.com/juliana-vieira/pipeline_linguagens_repos.git
   cd pipeline_linguagens_repos

2. **Access Token Setup:**:
   To avoid rate limits when accessing the GitHub API, it's recommended to configure a personal access token.

   - Create an access token on GitHub.
   - Store the token in an environment variable called `GITHUB_TOKEN` or in a `.env` file:
     ```plaintext
     GITHUB_TOKEN=seu_token_aqui
     ```

3. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt

## Usage Example

To extract data on programming languages used by companies, set up the `company_list` with the desired usernames:

```python
from processamento import DadosRepositorios

# List of companies (or any GitHub user) to be analyzed
company_list = ["amzn", "netflix", "spotify", "discord"]

for company in company_list:

    dados = DadosRepositorios(company) # Creates an object of the DadosRepositorios class, which has data extraction methods utilizing the GitHub API
    dados.to_dataframe() # Converts the data to a pandas DataFrame
    dados.save_csv() # Saves the file as CSV in the "data" folder
```
The code above will create a CSV file for each profile listed in company_list, containing data on the main programming languages used by each company, and save these files in the "data" folder.

The DadosRepositorios class contains all the methods necessary to extract, transform, and save the data within the business context.

üéâ Thank you for checking out this project! üòä
